# **Chatbot H√≠brido para WhatsApp: JKL Ve√≠culos (com IA 100% Local)**

## **üìñ Descri√ß√£o**

Este projeto demonstra a cria√ß√£o de um chatbot para WhatsApp que combina uma abordagem baseada em regras (menu de op√ß√µes) com um assistente de Intelig√™ncia Artificial 100% gratuito e local, usando **LangChain** e **Ollama**.

O chatbot √© capaz de:

* Guiar usu√°rios atrav√©s de um menu de op√ß√µes fixas para tarefas comuns.  
* Responder perguntas abertas e complexas com base em uma base de conhecimento personalizada, **sem custos de API e sem enviar dados para fora**.

## **üèõÔ∏è Arquitetura da Solu√ß√£o**

A solu√ß√£o opera de forma h√≠brida:

1. **Interface (WhatsApp)**: O cliente interage com a loja.  
2. **Orquestrador (Node.js \- whatsapp-web.js)**: Gerencia a conex√£o com o WhatsApp.  
   * **L√≥gica de Regras**: Responde a comandos de menu (ex: "1").  
   * **L√≥gica de IA**: Se for uma pergunta aberta, chama o c√©rebro de IA.  
3. **C√©rebro de IA (Python \+ LangChain \+ Ollama)**:  
   * O script Node.js chama o script Python (chatbot\_ia\_jkl.py).  
   * O script Python usa **LangChain** para carregar a base\_conhecimento\_jkl.md.  
   * O LangChain se comunica com o **Ollama** (rodando no mesmo computador) para usar um modelo de IA local (como o gemma:2b do Google).  
   * O modelo gera uma resposta baseada no conhecimento da JKL.  
   * A resposta √© impressa no console (stdout).  
4. **Retorno**: O Node.js captura a resposta e a envia ao usu√°rio.

## **üõ†Ô∏è Tecnologias Utilizadas**

* **Orquestra√ß√£o**: Node.js, whatsapp-web.js, child\_process  
* **Linguagem de IA**: Python 3.9+  
* **Framework de IA**: LangChain  
* **Servidor de IA Local**: Ollama  
* **Modelo de Linguagem**: Google Gemma (ou qualquer modelo do Ollama)  
* **Base de Conhecimento**: Arquivo Markdown (.md)

## **‚öôÔ∏è Instala√ß√£o e Configura√ß√£o**

### **Parte 1: Ambiente Node.js (WhatsApp)**

1. Tenha o Node.js instalado.  
2. Instale as depend√™ncias:  
   npm install whatsapp-web.js qrcode-terminal

### **Parte 2: Ambiente de IA Local (Ollama)**

1. **Instale o Ollama:** Baixe e instale o programa em: [https://ollama.com/](https://ollama.com/)  
2. **Baixe o Modelo de IA:** Ap√≥s instalar o Ollama, abra seu terminal e execute o comando abaixo para baixar o modelo gemma:2b (aprox. 2.7 GB):  
   ollama pull gemma:2b

3. **Verifique se o Ollama est√° rodando:** O Ollama deve estar em execu√ß√£o em segundo plano.

### **Parte 3: Ambiente Python (LangChain)**

1. Tenha o Python 3.9+ instalado.  
2. Crie e ative um ambiente virtual:  
   python \-m venv venv  
   source venv/bin/activate  \# macOS/Linux  
   \# venv\\Scripts\\activate    \# Windows

3. Instale as depend√™ncias de Python (usando o novo requirements.txt):  
   pip install \-r requirements.txt

4. **N√£o √© necess√°rio um arquivo .env\!** A autentica√ß√£o √© local.

## **üöÄ Como Executar**

1. **Inicie o Ollama**: Certifique-se de que o aplicativo Ollama esteja em execu√ß√£o.  
2. Inicie o bot do WhatsApp:  
   Abra um terminal e execute o script Node.js.  
   node app.js

   Escaneie o QR Code com seu celular para conectar.  
3. **Teste a Intera√ß√£o**:  
   * Envie "Oi" para ver o menu.  
   * Teste uma op√ß√£o do menu, como "1".  
   * Fa√ßa uma pergunta aberta da base\_conhecimento\_jkl.md, como:  
     * "Qual a filosofia da empresa?"  
     * "Voc√™s oferecem garantia estendida?"  
     * "Como funciona a avalia√ß√£o do meu carro na troca?"

O bot ir√° alternar entre as respostas programadas e as respostas geradas pela sua IA local e gratuita.
